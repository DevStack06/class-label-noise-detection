{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost code start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "import random\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "weight_list=[]\n",
    "\n",
    "class AdaBoost:\n",
    "  def __init__(self, M):\n",
    "    self.M = M\n",
    "\n",
    "  def fit(self, X, Y):\n",
    "    self.models = []\n",
    "    self.alphas = []\n",
    "\n",
    "    N, _ = X.shape\n",
    "    W = np.ones(N) / N\n",
    "\n",
    "    for m in range(self.M):\n",
    "      tree = DecisionTreeClassifier(max_depth=1)\n",
    "      tree.fit(X, Y, sample_weight=W)\n",
    "      P = tree.predict(X)\n",
    "\n",
    "      err = W.dot(P != Y)\n",
    "      alpha = 0.5*(np.log(1 - err) - np.log(err))\n",
    "\n",
    "      W = W*np.exp(-alpha*Y*P) # vectorized form\n",
    "      W = W / W.sum() # normalize so it sums to 1\n",
    "      weight_list.append(W)\n",
    "\n",
    "      self.models.append(tree)\n",
    "      self.alphas.append(alpha)\n",
    "\n",
    "  def predict(self, X):\n",
    "    # NOT like SKLearn API\n",
    "    # we want accuracy and exponential loss for plotting purposes\n",
    "    N, _ = X.shape\n",
    "    FX = np.zeros(N)\n",
    "    for alpha, tree in zip(self.alphas, self.models):\n",
    "      FX += alpha*tree.predict(X)\n",
    "    return np.sign(FX), FX\n",
    "\n",
    "  def score(self, X, Y):\n",
    "    # NOT like SKLearn API\n",
    "    # we want accuracy and exponential loss for plotting purposes\n",
    "    P, FX = self.predict(X)\n",
    "    L = np.exp(-Y*FX).mean()\n",
    "    return np.mean(P == Y), L\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    cancer = datasets.load_breast_cancer()\n",
    "    Y=cancer.target\n",
    "    Y[Y == 0] = -1\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(cancer.data, Y, test_size=0.2,random_state=109) # 70% training and 30% test\n",
    "   # make the targets -1,+1\n",
    "    per=(Ytrain.shape[0])*(10/100) #20% data will be mislabeled\n",
    "\n",
    "    k=random.sample(range(Ytrain.shape[0]), int(per)) #list of index no. of mislabeled data\n",
    "    for i in k:\n",
    "        if Ytrain[i-1]==1:\n",
    "            Ytrain[i-1]=-1;\n",
    "        else:\n",
    "            Ytrain[i-1]=1\n",
    "#mislabeled data created here till now\n",
    "    model = AdaBoost(10)\n",
    "    model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list=np.array(weight_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observing the wieght of instances\n",
    "#print(wieght_list)\n",
    "a=len(weight_list)\n",
    "\n",
    "#sorting data and finding mean\n",
    "nm=[] \n",
    "nm=np.mean(weight_list, axis=0)\n",
    "#print(nm)\n",
    "a=len(nm)\n",
    "Q=[]\n",
    "x=[]\n",
    "#print(a)\n",
    "for i in range(a):\n",
    "    x=[i,nm[i]]\n",
    "    Q.append(x)\n",
    "    x=[]\n",
    "#print(Q)\n",
    "Q.sort(key = lambda Q: Q[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeResult(mode=array([0.00103373]), count=array([71]))\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "yp=np.array(nm)\n",
    "mode=stats.mode(nm)\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count=Counter(nm)\n",
    "count1=Counter(nm)\n",
    "# print(type(count))\n",
    "nm2=nm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0010337337762558207: 71, 0.0012314062691593125: 68, 0.0010650151490398635: 65, 0.0009253712034402558: 29, 0.004521323871206521: 21, 0.0025264250310499795: 18, 0.0090718500669782: 17, 0.0007188453218357898: 16, 0.0008093885322242072: 16, 0.0010399917109167698: 15, 0.002164050724876334: 14, 0.010950191706367629: 14, 0.0011959004792315648: 10, 0.0009066506971284842: 9, 0.0007052285950477598: 6, 0.004168860896836484: 6, 0.000790067740314596: 6, 0.0016334558290290089: 4, 0.002471447835750366: 4, 0.005189411618212523: 4, 0.002095924698976401: 4, 0.0018191572693676598: 3, 0.003624349208874487: 3, 0.00219581680655393: 3, 0.010526842578661618: 3, 0.0014101460041119457: 2, 0.0008359721059619333: 2, 0.002109553519608255: 2, 0.00538380049833042: 2, 0.0010564427977506705: 2, 0.007118377004926751: 2, 0.0024618799633223075: 2, 0.001607335211202343: 2, 0.0046893014309660214: 1, 0.0029490153370896853: 1, 0.002145381460263727: 1, 0.005155067121065213: 1, 0.001380490864350724: 1, 0.0010796011553380262: 1, 0.004614680080313907: 1, 0.0015652574936057273: 1, 0.004658944817207768: 1, 0.0021435956881105567: 1})\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#mode calculating\n",
    "print(count1)\n",
    "modeg=statistics.mode(nm)\n",
    "jk=float(count1[0])\n",
    "print(jk)\n",
    "ne=[]\n",
    "for j in range(Xtrain.shape[0]):\n",
    "    if nm2[j]==modeg:\n",
    "        ne.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 17, 35, 41, 42, 53, 64, 73, 77, 83, 102, 110, 113, 120, 121, 130, 135, 144, 156, 159, 166, 167, 168, 181, 183, 185, 193, 196, 202, 208, 215, 217, 219, 220, 238, 241, 243, 247, 250, 251, 257, 258, 260, 265, 277, 287, 294, 308, 309, 317, 321, 330, 340, 342, 343, 345, 349, 355, 360, 371, 377, 388, 390, 395, 409, 411, 415, 426, 450, 452, 454]\n"
     ]
    }
   ],
   "source": [
    "print(ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b): \n",
    "    a_set = set(a) \n",
    "    b_set = set(b) \n",
    "    \n",
    "    if (a_set & b_set): \n",
    "        wq=a_set & b_set \n",
    "    else: \n",
    "        print(\"No common elements\")  \n",
    "    return wq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "45\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "## culprit points \n",
    "a=set(ne)\n",
    "b=set(k)\n",
    "re=a&b\n",
    "print(len(ne))# culprit points\n",
    "print(len(k)) #total number of mislabeled point we introduced\n",
    "print(len(re))#detected points as a real mislabeled points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = SVC(kernel='linear') \n",
    "\n",
    "clf1 = KNeighborsClassifier() \n",
    "\n",
    "clf2 = DecisionTreeClassifier() \n",
    "\n",
    "clf3 = GaussianNB() \n",
    "\n",
    "\n",
    "# cancer=datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n",
      "0.9473684210526315\n",
      "0.8596491228070176\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "clf.fit(Xtrain, Ytrain)\n",
    "y_pred_mis = clf.predict(Xtest)\n",
    "clf1.fit(Xtrain, Ytrain)\n",
    "y_pred_mis1 = clf1.predict(Xtest)\n",
    "clf2.fit(Xtrain, Ytrain)\n",
    "y_pred_mis2 = clf2.predict(Xtest)\n",
    "clf3.fit(Xtrain, Ytrain)\n",
    "y_pred_mis3 = clf3.predict(Xtest)\n",
    "\n",
    "\n",
    "print(accuracy_score(Ytest, y_pred_mis))\n",
    "print(accuracy_score(Ytest, y_pred_mis1))\n",
    "print(accuracy_score(Ytest, y_pred_mis2))\n",
    "print(accuracy_score(Ytest, y_pred_mis3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ne:\n",
    "    if(Ytrain[i]==1):\n",
    "        Ytrain[i]=-1\n",
    "    else:\n",
    "        Ytrain[i]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##accuracy after fliping the culprit points \n",
    "clf.fit(Xtrain, Ytrain)\n",
    "y_pred_mis = clf.predict(Xtest)\n",
    "clf1.fit(Xtrain, Ytrain)\n",
    "y_pred_mis1 = clf1.predict(Xtest)\n",
    "clf2.fit(Xtrain, Ytrain)\n",
    "y_pred_mis2 = clf2.predict(Xtest)\n",
    "clf3.fit(Xtrain, Ytrain)\n",
    "y_pred_mis3 = clf3.predict(Xtest)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n",
      "0.9473684210526315\n",
      "0.8421052631578947\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Ytest, y_pred_mis))\n",
    "print(accuracy_score(Ytest, y_pred_mis1))\n",
    "print(accuracy_score(Ytest, y_pred_mis2))\n",
    "print(accuracy_score(Ytest, y_pred_mis3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
